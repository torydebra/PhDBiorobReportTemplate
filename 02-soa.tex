\newpage
\section{State of art and proposed innovation} 
% [max 1 page, max 20 refs]
%Properly frame the research in the literature. Which is the gap you plan to bridge? Which are the open issues you aim to address? 
%(If the objectives of the project do not change during the 3-years, this section could be filled only the first year and modified only by adding new relevant works published). 

Robotic teleoperation is one of the oldest fields in robotics~\cite{Goertz1952},⁠ but yet an active and evolving research topic. The increasing robot capabilities have expanded the possible application of teleoperation in very different areas such as in disaster response~\cite{Liu2013}⁠⁠, construction industry~\cite{Carra2018}, assistive scenarios~\cite{Petrich2022}, for permitting the remote command and execution of complex loco-manipulation tasks. At the same time, the improved capabilities of recent mobile/legged manipulation platforms have increased the complexity of remotely commanding them, hence augmenting the burden of the operator in executing remote tasks. This has motivated works, which target to develop more intuitive and smarter interaction and commanding interfaces for the teleoperation the remotely operated robot.

Flexible interfaces that attempt to track multiple operator inputs have been explored, based on Inertial Measurement Unit (IMU) devices to direct teleoperate humanoids robots~\cite{Darvish23}. In these cases, the complexity of the slave robot is handled by sending multiple inputs provided by a sensorized full body interface. The work in~\cite{Wu2019}⁠ exploited a full body IMU-based suit combined with a human center of pressure model and a tele-impedance interface to control the locomotion and manipulation actions. Tele-impedance control enriches the command sent to the remote robot by combing the master estimated position and the stiffness references obtained through an Electromyography (EMG) interface~\cite{Ajoudani2012}⁠. Another class of approach for the teleoperation is the exploitation of exoskeletons with dissimilar kinematics respect to the robot to control~\cite{Rebelo2012}⁠. This introduces challenges in how to map the master and slave kinematics at best, and how to design the cumbersome exoskeleton interface to be more comfortable as possible when worn by the operator. Despite all the provided solutions for the teleoperation of complex loco-manipulation platforms, one of the most intuitive ways to guide the robot is by physically interacting with its body to drive it along the desired motion to teach or guide during collaborative tasks. Indeed, physical Human Robot Interaction (pHRI) can assist the operator in accomplishing collaborative tasks in collaboration with the robot~\cite{Cherubini2016, Kruger2009}⁠. 

To augment the robot autonomy, providing smarter teleoperation interface which permits to relieve the operator from commanding each aspect of the tasks, more intelligent human-robot teleoperation interfaces have been explored, providing various levels of shared control or shared autonomy~\cite{Selvaggio2021}. An idea is to give full autonomy to the robotic system to handle the \enquote{low-level} operations, while the human operator provides the \enquote{high-level} commands. This concept is supported by the fact that, for example, humans are better than machines in processing visual information, but they are prone to errors due to fatigue when a precise end-effector trajectory is needed~\cite{Yang2018}⁠. In some relevant works is shown that the teleoperated robot autonomously points the gripper in a specific direction~\cite{Abi2016}, overrides the commands of the human operator to avoid unsafe regions [17] and obstacles~\cite{Masone2018}, and maintains the dual-arm grasp on a transported object~\cite{Shahbazi2017, Laghi2018}, [C.3], [C.5].

In parallel, several works have coupled the remote robot control with a sensory feedback channel that supplements the visual domain, encompassing an array of stimuli like haptic cues to leverage the human sense of touch~\cite{Dargahi2004, Pacchierotti2015}. Wearable interfaces, in particular, allow to deliver a variety of cutaneous cues (e.g., skin stretch, vibration, temperature) to different body parts, resulting in unobtrusive, flexible devices capable of transmitting different kinds of information to the user~\cite{pacchierotti2017wearable}. 
%

Despite all the advancements in these technologies, it is still a challenge to develop a teleoperation interface that allows the control of complex robots while maintaining a simple structure, not overwhelming the operator with difficult-to-learn and cumbersome human robot interfaces. This is the key aspect of the research, which has provided new kind of intuitive teleoperation paradigms and validate them with complex mobile manipulators.